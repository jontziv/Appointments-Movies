{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7851bea8",
   "metadata": {},
   "source": [
    "## Machine Learning & Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374ff5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11bcac49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Noshow</th>\n",
       "      <th>SMSreceived</th>\n",
       "      <th>Age</th>\n",
       "      <th>GenderM</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>TimeGapDays</th>\n",
       "      <th>prevNoshow</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>WaitingTimeCategory</th>\n",
       "      <th>TotalConditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Long Wait</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Long Wait</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Long Wait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Long Wait</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Long Wait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Same Day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Same Day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Same Day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Same Day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110524</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Same Day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110525 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Noshow  SMSreceived   Age  GenderM  Scholarship  Hipertension  \\\n",
       "0            0            1  84.0     True            0             1   \n",
       "1            0            1  83.0    False            0             1   \n",
       "2            0            1  74.0    False            0             0   \n",
       "3            0            1  70.0    False            0             1   \n",
       "4            0            1  87.0    False            0             0   \n",
       "...        ...          ...   ...      ...          ...           ...   \n",
       "110520       0            0  54.0     True            0             0   \n",
       "110521       0            0  43.0    False            0             0   \n",
       "110522       0            0  27.0     True            0             0   \n",
       "110523       0            0  30.0    False            0             0   \n",
       "110524       0            0  27.0    False            0             0   \n",
       "\n",
       "        Diabetes  Alcoholism  Handcap  TimeGapDays  prevNoshow    WeekDay  \\\n",
       "0              1           0        1          115           0     Friday   \n",
       "1              0           0        0          115           0     Friday   \n",
       "2              0           0        0          109           0     Friday   \n",
       "3              1           0        0          109           0     Friday   \n",
       "4              0           0        0          109           0     Friday   \n",
       "...          ...         ...      ...          ...         ...        ...   \n",
       "110520         0           0        0            0           0  Wednesday   \n",
       "110521         0           0        0            0           1  Wednesday   \n",
       "110522         0           0        0            0           0  Wednesday   \n",
       "110523         0           0        0            0           0  Wednesday   \n",
       "110524         0           0        0            0           0  Wednesday   \n",
       "\n",
       "       AgeCategory WaitingTimeCategory  TotalConditions  \n",
       "0           Senior           Long Wait                3  \n",
       "1           Senior           Long Wait                1  \n",
       "2           Senior           Long Wait                0  \n",
       "3           Senior           Long Wait                2  \n",
       "4           Senior           Long Wait                0  \n",
       "...            ...                 ...              ...  \n",
       "110520       Adult            Same Day                0  \n",
       "110521       Adult            Same Day                0  \n",
       "110522       Adult            Same Day                0  \n",
       "110523       Adult            Same Day                0  \n",
       "110524       Adult            Same Day                0  \n",
       "\n",
       "[110525 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"appointments.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9be41c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110525 entries, 0 to 110524\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Noshow               110525 non-null  int64  \n",
      " 1   SMSreceived          110525 non-null  int64  \n",
      " 2   Age                  110525 non-null  float64\n",
      " 3   GenderM              110525 non-null  bool   \n",
      " 4   Scholarship          110525 non-null  int64  \n",
      " 5   Hipertension         110525 non-null  int64  \n",
      " 6   Diabetes             110525 non-null  int64  \n",
      " 7   Alcoholism           110525 non-null  int64  \n",
      " 8   Handcap              110525 non-null  int64  \n",
      " 9   TimeGapDays          110525 non-null  int64  \n",
      " 10  prevNoshow           110525 non-null  int64  \n",
      " 11  WeekDay              110525 non-null  object \n",
      " 12  AgeCategory          110525 non-null  object \n",
      " 13  WaitingTimeCategory  110525 non-null  object \n",
      " 14  TotalConditions      110525 non-null  int64  \n",
      "dtypes: bool(1), float64(1), int64(10), object(3)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e592d",
   "metadata": {},
   "source": [
    "### Brainstorming / Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f426b9a",
   "metadata": {},
   "source": [
    "To develop a classification model that can predict no-shows in medical appointments effectively, we will follow a structured workflow. This workflow encompasses data preprocessing, exploratory data analysis (EDA), feature selection and engineering, model selection, training, evaluation, and finally, model refinement. Here is an outline of the required steps:\n",
    "\n",
    "1. Understanding the Data\n",
    "Initial Inspection: Although the dataset is already cleaned, review the data types, check for any anomalies or inconsistencies, and ensure there are no missing values or outliers that could affect the model's performance.\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "Statistical Summary: Use descriptive statistics to understand the central tendency, dispersion, and shape of the datasetâ€™s distribution.\n",
    "Visualization: Create visualizations (histograms, box plots, scatter plots) to understand relationships between features, identify patterns or outliers, and visualize the distribution of variables.\n",
    "Correlation Analysis: Analyze the correlation between different features and the target variable to identify potential predictors.\n",
    "3. Feature Engineering and Selection\n",
    "Encoding Categorical Variables: Convert categorical variables into a form that could be provided to ML algorithms (e.g., one-hot encoding for nominal categories).\n",
    "Feature Selection: Use statistical tests and algorithms (like SelectKBest, or feature importance from ensemble methods) to select the most relevant features to reduce dimensionality and improve model performance.\n",
    "Feature Engineering: Derive new features from existing ones to better capture the underlying patterns and relationships, if necessary.\n",
    "4. Data Preprocessing\n",
    "Scaling/Normalization: Scale or normalize features if you're using models sensitive to the magnitude of features, such as SVM, k-NN, or neural networks.\n",
    "Handling Imbalanced Data: If the target variable is imbalanced, consider techniques like SMOTE, undersampling, or oversampling to balance the classes.\n",
    "Train-Test Split: Divide the dataset into training and testing sets to evaluate the model's performance on unseen data.\n",
    "5. Model Selection\n",
    "Choose Several Models: Start with a variety of models suited for classification tasks (e.g., Logistic Regression, Random Forest, Gradient Boosting, SVM, and Neural Networks) to see which performs best on your dataset.\n",
    "Cross-Validation: Use cross-validation to assess the performance of models more reliably.\n",
    "6. Model Training and Tuning\n",
    "Hyperparameter Tuning: Use grid search or random search to find the best parameters for each model.\n",
    "Training: Train the models using the training set and the best-found parameters.\n",
    "7. Model Evaluation\n",
    "Select Evaluation Metrics: Use metrics like accuracy, precision, recall, F1 score, and ROC-AUC to evaluate model performance.\n",
    "Confusion Matrix: Analyze the confusion matrix for a detailed understanding of model performance across different classes.\n",
    "8. Model Refinement\n",
    "Ensemble Methods: Consider using ensemble methods (e.g., Stacking, Bagging, Boosting) to improve prediction performance by combining several models.\n",
    "Feature Importance Review: Review the importance of features for the best-performing models and consider revising feature selection or engineering steps.\n",
    "9. Final Model Selection\n",
    "Choose the Best Model: Select the model that offers the best balance between performance metrics and complexity.\n",
    "Validation: Use the test set to validate the final model's performance to ensure it generalizes well to new, unseen data.\n",
    "10. Deployment (Optional)\n",
    "Model Deployment: Prepare the model for deployment in a production environment, considering API development for integration with existing healthcare systems.\n",
    "Monitoring and Maintenance: Set up a system for monitoring the model's performance over time and updating it as necessary with new data or to adjust for concept drift.\n",
    "This workflow is iterative, and you may need to loop back to earlier steps based on the insights you gain or the performance of your models during evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ec7eb3",
   "metadata": {},
   "source": [
    "Focusing on Gradient Boosting Machines (GBMs) for the appointments dataset, especially when aiming to maximize prediction accuracy while also valuing simplicity and the integration of data preprocessing, LightGBM emerges as the most suitable choice. Here's why:\n",
    "\n",
    "LightGBM\n",
    "LightGBM is a gradient boosting framework that uses tree-based learning algorithms and is designed for speed and efficiency. It stands out for several reasons that match your criteria:\n",
    "\n",
    "1. Efficiency and Speed:\n",
    "LightGBM is optimized for performance and speed, which allows it to handle large datasets more efficiently than other GBM frameworks. This makes it particularly suitable for the appointments dataset, which may have a significant number of entries and features.\n",
    "2. Handling Sparse Data:\n",
    "The appointments dataset may contain sparse features after preprocessing (e.g., one-hot encoded categorical variables). LightGBM is capable of efficiently handling sparse data, improving computational efficiency without sacrificing model performance.\n",
    "3. Categorical Feature Support:\n",
    "Unlike other GBM frameworks that require categorical features to be pre-processed into numerical values, LightGBM can directly handle categorical features. This reduces the need for extensive data preprocessing, such as one-hot encoding, thereby simplifying the model-building pipeline.\n",
    "4. Lower Memory Usage:\n",
    "LightGBM uses a histogram-based algorithm that buckets continuous feature values into discrete bins. This approach significantly reduces memory usage, making it more suitable for datasets with many continuous or high-cardinality features.\n",
    "5. Higher Accuracy:\n",
    "With its novel techniques for tree growing (Gradient-based One-Side Sampling and Exclusive Feature Bundling), LightGBM can achieve higher accuracy levels on various datasets with less tuning of hyperparameters compared to other models.\n",
    "6. Ease of Use:\n",
    "LightGBM offers an easy-to-use Python API, which is compatible with scikit-learn. This makes model training, hyperparameter tuning, and cross-validation straightforward, especially for users already familiar with the scikit-learn ecosystem.\n",
    "Integration with Data Preprocessing\n",
    "Given its ability to directly handle categorical features and efficiently manage sparse data, LightGBM minimizes the need for complex data preprocessing steps. However, basic preprocessing such as handling missing values (if any), scaling or normalization (depending on the context), and feature selection should still be conducted to optimize model performance.\n",
    "Conclusion\n",
    "LightGBM stands out as the most suitable Gradient Boosting Machine model for the appointments dataset, balancing the need for high predictive accuracy with simplicity and efficient data preprocessing integration. Its performance and ease of use make it a compelling choice for both beginners and advanced users looking to develop a predictive model for no-show appointments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b646e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15cd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "951b8509",
   "metadata": {},
   "source": [
    "### Data Proprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd256af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935c2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "# Convert categorical features to category type\n",
    "categorical_features = ['GenderM', 'WeekDay', 'AgeCategory', 'WaitingTimeCategory']\n",
    "for feature in categorical_features:\n",
    "    df[feature] = df[feature].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23c0471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110525 entries, 0 to 110524\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count   Dtype   \n",
      "---  ------               --------------   -----   \n",
      " 0   Noshow               110525 non-null  int64   \n",
      " 1   SMSreceived          110525 non-null  int64   \n",
      " 2   Age                  110525 non-null  float64 \n",
      " 3   GenderM              110525 non-null  category\n",
      " 4   Scholarship          110525 non-null  int64   \n",
      " 5   Hipertension         110525 non-null  int64   \n",
      " 6   Diabetes             110525 non-null  int64   \n",
      " 7   Alcoholism           110525 non-null  int64   \n",
      " 8   Handcap              110525 non-null  int64   \n",
      " 9   TimeGapDays          110525 non-null  int64   \n",
      " 10  prevNoshow           110525 non-null  int64   \n",
      " 11  WeekDay              110525 non-null  category\n",
      " 12  AgeCategory          110525 non-null  category\n",
      " 13  WaitingTimeCategory  110525 non-null  category\n",
      " 14  TotalConditions      110525 non-null  int64   \n",
      "dtypes: category(4), float64(1), int64(10)\n",
      "memory usage: 9.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb84ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X = df.drop('Noshow', axis=1)  # Features\n",
    "y = df['Noshow']                # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b145a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMSreceived</th>\n",
       "      <th>Age</th>\n",
       "      <th>GenderM</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>TimeGapDays</th>\n",
       "      <th>prevNoshow</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>WaitingTimeCategory</th>\n",
       "      <th>TotalConditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87976</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Same Day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88530</th>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Same Day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34653</th>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Medium Wait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Teenager</td>\n",
       "      <td>Medium Wait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57389</th>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Short Wait</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73032</th>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Medium Wait</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88812</th>\n",
       "      <td>1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Long Wait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60253</th>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Long Wait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42942</th>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Medium Wait</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15192</th>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Same Day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88420 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SMSreceived   Age GenderM  Scholarship  Hipertension  Diabetes  \\\n",
       "87976            0  26.0    True            0             0         0   \n",
       "88530            0  38.0    True            0             0         0   \n",
       "34653            1  61.0   False            0             0         0   \n",
       "4839             1  12.0   False            1             0         0   \n",
       "57389            0  81.0   False            0             1         0   \n",
       "...            ...   ...     ...          ...           ...       ...   \n",
       "73032            1  49.0    True            0             1         0   \n",
       "88812            1  69.0   False            0             0         0   \n",
       "60253            0  50.0   False            1             0         0   \n",
       "42942            0  29.0   False            0             0         0   \n",
       "15192            0  20.0    True            0             0         0   \n",
       "\n",
       "       Alcoholism  Handcap  TimeGapDays  prevNoshow    WeekDay AgeCategory  \\\n",
       "87976           0        0            0           0  Wednesday       Adult   \n",
       "88530           0        0            0           0  Wednesday       Adult   \n",
       "34653           0        0            7           1  Wednesday      Senior   \n",
       "4839            0        0            6           0     Monday    Teenager   \n",
       "57389           0        0            2           0  Wednesday      Senior   \n",
       "...           ...      ...          ...         ...        ...         ...   \n",
       "73032           0        0            6           0  Wednesday       Adult   \n",
       "88812           0        0           36           0   Thursday      Senior   \n",
       "60253           0        0           16           0   Thursday       Adult   \n",
       "42942           0        0           11           0     Friday       Adult   \n",
       "15192           0        0            0           0  Wednesday       Adult   \n",
       "\n",
       "      WaitingTimeCategory  TotalConditions  \n",
       "87976            Same Day                0  \n",
       "88530            Same Day                0  \n",
       "34653         Medium Wait                0  \n",
       "4839          Medium Wait                0  \n",
       "57389          Short Wait                1  \n",
       "...                   ...              ...  \n",
       "73032         Medium Wait                1  \n",
       "88812           Long Wait                0  \n",
       "60253           Long Wait                0  \n",
       "42942         Medium Wait                0  \n",
       "15192            Same Day                0  \n",
       "\n",
       "[88420 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "137a246c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20194526125311016"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad73c7",
   "metadata": {},
   "source": [
    "Given that the no-show rate in your dataset is 20%, the class imbalance is moderate. In such cases, handling the imbalance can potentially improve model performance, especially for metrics such as precision, recall, and the F1 score, which are more sensitive to imbalanced classes than accuracy.\n",
    "\n",
    "Recommendations:\n",
    "Use of LightGBM's Weight Parameter: One of the simplest and most effective ways to handle class imbalance directly with LightGBM is through its weight parameter during dataset construction. This method adjusts the weight of different classes in the loss function, making the model more sensitive to the minority class. It's straightforward to implement and does not require modifying the original dataset.\n",
    "\n",
    "To apply this, you can use the class_weight parameter in LightGBM's training function or manually specify weights for each instance in the training dataset. LightGBM can automatically calculate the appropriate weights if you specify class_weight='balanced' when creating the model. This approach is computationally efficient and keeps the original data distribution intact.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique): SMOTE is another option where synthetic examples of the minority class are generated to balance the dataset. It can be effective but also introduces synthetic data, which might lead to overfitting or the model learning artifacts that do not exist in the real data.\n",
    "\n",
    "Comparing the Two Approaches:\n",
    "Integration and Simplicity: Using LightGBM's weight parameter is more integrated and simpler as it doesn't require external preprocessing of the data. Adjusting class weights is a parameter tuning step rather than a data manipulation step, keeping the pipeline cleaner.\n",
    "\n",
    "Data Distribution: LightGBM's approach maintains the original data distribution, only adjusting the model's focus during training. In contrast, SMOTE alters the data distribution by adding synthetic examples, which can be beneficial or detrimental, depending on how well these synthetic examples represent the real-world data distribution.\n",
    "\n",
    "Effectiveness: The effectiveness of each approach can vary depending on the dataset and the specific problem. It's often recommended to try both approaches (if the imbalance is significantly impacting model performance) and compare results using cross-validation.\n",
    "\n",
    "Conclusion:\n",
    "Given the moderate imbalance and the need for simplicity, starting with LightGBM's weight parameter to handle class imbalance is advisable. This approach is straightforward, does not require additional data processing steps, and allows you to maintain the original data distribution while addressing class imbalance directly within the model training process.\n",
    "\n",
    "If you find that handling imbalance through LightGBM's weight parameter does not sufficiently improve model performance, consider experimenting with SMOTE or other sampling techniques as a secondary step. Always validate the impact of these techniques through cross-validation and by examining various performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065f503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cb81b87",
   "metadata": {},
   "source": [
    "### Fitting a Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52674b09",
   "metadata": {},
   "source": [
    "After completing the data preprocessing, the next logical step in your workflow is to fit a baseline model. This approach allows you to establish a performance benchmark for your classification task with the appointments dataset. Once you have a baseline, you can proceed with hyperparameter tuning and optimization to improve the model's performance. Here's a detailed outline of the steps:\n",
    "\n",
    "1. Fitting a Baseline Model\n",
    "Objective: The goal of the baseline model is to provide a simple yet reasonable performance metric that you can use to compare more complex models or tuned versions of the same model.\n",
    "Process: Use LightGBM with its default parameters to fit the model on your training set. Do not worry about tuning hyperparameters at this stage.\n",
    "Evaluation: Evaluate the baseline model using appropriate metrics (accuracy, precision, recall, F1 score, ROC-AUC, etc.) based on your training and validation sets. This will give you an initial understanding of how well the model performs with minimal adjustments.\n",
    "\n",
    "2. Hyperparameter Tuning and Optimization\n",
    "After establishing a baseline, the next step is to optimize the model by tuning its hyperparameters. This process can significantly improve the model's predictive performance.\n",
    "\n",
    "Selection of Hyperparameters: Identify key hyperparameters for LightGBM that influence model performance, such as num_leaves, max_depth, min_child_samples, learning_rate, and n_estimators.\n",
    "Tuning Techniques: Utilize grid search, random search, or more sophisticated algorithms like Bayesian optimization to explore the hyperparameter space efficiently.\n",
    "Cross-Validation: Employ cross-validation (e.g., k-fold cross-validation) to assess the model's performance reliably across different subsets of the data. This helps ensure that your model generalizes well.\n",
    "Evaluation Metrics: Continue using the same evaluation metrics as for the baseline model to consistently compare performance improvements.\n",
    "\n",
    "\n",
    "3. Model Refinement\n",
    "Based on the results of hyperparameter tuning, refine your model by:\n",
    "\n",
    "Selecting the best-performing set of hyperparameters.\n",
    "Reassessing feature importance and considering additional feature engineering if necessary.\n",
    "Potentially exploring more advanced LightGBM features, such as using custom objective functions or boosting from an existing model if iterative improvements are needed.\n",
    "\n",
    "4. Validation\n",
    "Finally, validate the optimized model on a separate test set (which was not used during the training or tuning process) to assess its performance on unseen data. This step is crucial for understanding how well the model is likely to perform in a real-world scenario.\n",
    "\n",
    "5. Iteration\n",
    "Model development is an iterative process. Based on the insights gained during validation, you may choose to iterate on any of the previous steps (feature engineering, model tuning) to further improve performance.\n",
    "\n",
    "6. Documentation and Reporting\n",
    "Document the process, results, and decisions made throughout the modeling workflow. This includes documenting the baseline model's performance, changes made during hyperparameter tuning, final model configuration, and validation results.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "\n",
    "Starting with a baseline model is an efficient way to establish a performance benchmark. Following up with careful hyperparameter tuning and optimization helps in systematically improving the model's predictive accuracy. This structured approach ensures that enhancements are data-driven and incrementally beneficial, leading to a robust and optimized model for predicting no-shows in medical appointments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d5c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bf44fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LightGBM model\n",
    "lgbm_classifier = lgb.LGBMClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a74bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2232197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17854, number of negative: 70566\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 257\n",
      "[LightGBM] [Info] Number of data points in the train set: 88420, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201923 -> initscore=-1.374321\n",
      "[LightGBM] [Info] Start training from score -1.374321\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "lgbm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857b189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "494dcb21",
   "metadata": {},
   "source": [
    "### Evaluating the Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8af18ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90899cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30dafd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f87da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = lgbm_classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24e4af64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38765987, 0.02900508, 0.36433003, ..., 0.0427072 , 0.3297046 ,\n",
       "       0.23131117])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dd5cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78b96065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8008595340420719"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2951658b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8008595340420719\n",
      "Precision: 0.5637860082304527\n",
      "Recall: 0.06137992831541219\n",
      "F1 Score: 0.11070707070707073\n",
      "ROC AUC Score: 0.7400562129825863\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d31ae8",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d8d6228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the class_weight parameter to 'balanced'\n",
    "lgbm_classifier_balanced = lgb.LGBMClassifier(random_state=42, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79736f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 17854, number of negative: 70566\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 257\n",
      "[LightGBM] [Info] Number of data points in the train set: 88420, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data again, with the class_weight parameter set to 'balanced'\n",
    "lgbm_classifier_balanced.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e15050ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_classifier_balanced.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90072a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = lgbm_classifier_balanced.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0062a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c0485de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6008595340420719\n",
      "Precision: 0.313446888641616\n",
      "Recall: 0.8203405017921147\n",
      "F1 Score: 0.4535827088623273\n",
      "ROC AUC Score: 0.740229744410575\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb54411",
   "metadata": {},
   "source": [
    "The results from the LightGBM model adjusted for class imbalance using the class_weight='balanced' parameter show a significant shift in performance metrics compared to the baseline model. Let's analyze and compare these results:\n",
    "\n",
    "Accuracy <br>\n",
    "Baseline Model: 80.09%\n",
    "Adjusted Model: 60.09%\n",
    "The accuracy has decreased significantly. This indicates that the model, after adjustment, is less accurate overall in predicting both classes correctly. However, accuracy is not the best metric to rely on in imbalanced datasets as it can be misleading.\n",
    "\n",
    "Precision <br>\n",
    "Baseline Model: 56.38%\n",
    "Adjusted Model: 31.34%\n",
    "Precision has also decreased, indicating that of all appointments predicted as no-shows, a smaller percentage actually were no-shows compared to the baseline model. This suggests that the model is now more inclined to predict no-shows, even at the risk of being wrong more often.\n",
    "\n",
    "Recall <br>\n",
    "Baseline Model: 6.14%\n",
    "Adjusted Model: 82.03%\n",
    "There's a dramatic increase in recall, meaning that the model is now capable of identifying a much higher proportion of the actual no-shows. This is a crucial improvement for scenarios where missing out on actual no-shows (false negatives) is more critical than mistakenly labeling show-ups as no-shows (false positives).\n",
    "\n",
    "F1 Score <br>\n",
    "Baseline Model: 11.07%\n",
    "Adjusted Model: 45.36%\n",
    "The F1 score, which balances precision and recall, has increased markedly. This suggests that the adjusted model, despite making more false positive errors, is better balanced overall in terms of handling both classes, particularly in identifying the minority class (no-shows).\n",
    "\n",
    "ROC AUC Score <br>\n",
    "Baseline Model: 74.01%\n",
    "Adjusted Model: 74.02%\n",
    "The ROC AUC score remains almost unchanged, indicating that the model's ability to discriminate between the classes hasn't significantly improved or worsened from an overall perspective. This metric suggests that the model's overall predictive quality is stable, but the way it achieves its predictions has shifted towards favoring recall over precision.\n",
    "\n",
    "Interpretation and Implications <br>\n",
    "The adjustments made to address class imbalance have significantly improved the model's ability to identify the more critical minority class (no-shows), as evidenced by the substantial increase in recall and F1 score. However, this has come at the cost of reduced accuracy and precision, indicating a higher rate of false positives.\n",
    "\n",
    "In practical terms, if the goal is to minimize missed no-shows (for instance, in a healthcare setting where it's crucial to identify potential no-shows to reduce operational costs and scheduling inefficiencies), this trade-off might be acceptable or even desirable. However, if the cost of false alarms (incorrectly predicting no-shows) is high, the reduced precision might be a concern.\n",
    "\n",
    "This analysis underscores the importance of choosing performance metrics that align with the specific objectives of the predictive model and the costs associated with different types of errors. Adjusting for class imbalance has made the model more useful for scenarios prioritizing the identification of no-shows over the accurate prediction of all appointment outcomes.\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af06ecf0",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning (Theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065613c",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is a critical step in optimizing the performance of machine learning models, including LightGBM. It involves experimenting with different combinations of model parameters to find the set that produces the best results according to your chosen evaluation metrics. Hereâ€™s an overview of the most relevant parameters for LightGBM, sorted by their importance and a brief explanation of each:\n",
    "\n",
    "1. num_leaves\n",
    "The main parameter to control the complexity of the tree model. Theoretically, the number of leaves should be less than or equal to 2^(max_depth) to avoid overfitting. However, in practice, setting it to a value smaller than 2^(max_depth) can still lead to good results.\n",
    "2. max_depth\n",
    "Maximum tree depth for base learners, used to control over-fitting. Setting it to a positive value builds the trees up to the specified depth. The deeper the tree, the more complex the model, which can lead to better accuracy but increases the risk of overfitting.\n",
    "3. learning_rate\n",
    "Also known as shrinkage, this affects how quickly or slowly a model learns. A smaller learning rate requires more boosting rounds to achieve the same reduction in residual error as a larger learning rate.\n",
    "4. n_estimators\n",
    "The number of boosting rounds or trees to build. More trees can lead to better performance but also to longer training times and the potential for overfitting.\n",
    "5. min_child_samples (or min_data_in_leaf)\n",
    "The minimum number of data points needed to make a final decision at a leaf node. A higher number can prevent the model from learning relations that might be highly specific to the particular sample selected for a tree.\n",
    "6. min_child_weight\n",
    "Minimum sum of instance weight (hessian) needed in a child (leaf). If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning.\n",
    "7. subsample\n",
    "The subsample ratio of the training instances. Setting it to 0.5 means that LightGBM will randomly sample half of the training data to grow trees and this will prevent overfitting.\n",
    "8. colsample_bytree\n",
    "The subsample ratio of columns when constructing each tree. Subsampling occurs once for every tree constructed.\n",
    "9. reg_alpha and reg_lambda\n",
    "L1 and L2 regularization terms on weights respectively. They can be used to help prevent overfitting.\n",
    "Hyperparameter Tuning Process and Options:\n",
    "The process of hyperparameter tuning involves systematically searching through a range of hyperparameter values to find the combination that performs the best based on a predefined metric. Common strategies for hyperparameter tuning include:\n",
    "\n",
    "Grid Search: Exhaustively tries every combination of predefined ranges of hyperparameter values. It is simple to implement but can be very time-consuming, especially with a large number of parameters and wide ranges.\n",
    "\n",
    "Random Search: Randomly selects combinations of hyperparameters to try, which can be more efficient than grid search, especially when only a few hyperparameters significantly influence the model's performance.\n",
    "\n",
    "Bayesian Optimization: Uses a probabilistic model to predict the performance of different hyperparameter combinations and selects new combinations to try based on past results. It is more efficient than both grid and random search as it can quickly hone in on the most promising areas of the parameter space.\n",
    "\n",
    "Gradient-based Optimization: Uses gradient descent to find the minimum of the loss function in the hyperparameter space. This is less common for hyperparameter tuning due to the non-differentiability of most model performance metrics.\n",
    "\n",
    "Evolutionary Algorithms: Inspired by the process of natural selection, these algorithms use mechanisms such as mutation, crossover, and selection to evolve a set of hyperparameters towards better performance.\n",
    "\n",
    "Most Appropriate Setup for Our Example:\n",
    "Given the complexity of LightGBM and the potential high dimensionality of the hyperparameter space, Bayesian Optimization is a good balance between efficiency and effectiveness for our scenario. It intelligently navigates the hyperparameter space and often finds a good configuration faster than grid or random search, making it suitable for optimizing LightGBM's performance on the appointment no-show prediction task. Tools like Hyperopt, Optuna, or BayesianOptimization library in Python can be used to implement this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad49882",
   "metadata": {},
   "source": [
    "For Bayesian Optimization with LightGBM, you typically define a search space rather than a fixed grid of hyperparameter values. The search space specifies the range or distribution of values that the optimization algorithm will explore for each hyperparameter. Here's a promising search space for your LightGBM model that aims to balance model complexity with the risk of overfitting, considering the task of predicting appointment no-shows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "470a395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'num_leaves': (20, 100),  # Increase if model is underfitting\n",
    "    'max_depth': (3, 10),  # Increase if model is underfitting\n",
    "    'learning_rate': (0.01, 0.3),  # Decrease to make the model more robust\n",
    "    'n_estimators': (50, 1000),  # Increase if model is underfitting\n",
    "    'min_child_samples': (20, 500),  # Increase if model is overfitting\n",
    "    'min_child_weight': (1e-5, 1e-2, 'log-uniform'),  # Controls overfitting\n",
    "    'subsample': (0.5, 1.0),  # Lower to make the model more robust\n",
    "    'colsample_bytree': (0.5, 1.0),  # Lower to make the model more robust\n",
    "    'reg_alpha': (0, 1.0),  # L1 regularization\n",
    "    'reg_lambda': (0, 1.0),  # L2 regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f08168b",
   "metadata": {},
   "source": [
    "How to Use This Search Space:\n",
    "\n",
    "num_leaves and max_depth control the complexity of the model. A larger number of leaves or greater depth can capture more detailed patterns in the data but also increase the risk of overfitting.\n",
    "learning_rate and n_estimators are inversely related. A smaller learning rate generally requires more estimators (trees) to converge to a solution. Finding a balance between these two parameters is key to building a robust model.\n",
    "min_child_samples and min_child_weight help to prevent overfitting by making the model more conservative. They control the minimum number of samples or sum of weights in a leaf.\n",
    "subsample and colsample_bytree offer additional regularization by enabling stochastic gradient boosting, where each tree is trained on a subsample of the data and features.\n",
    "reg_alpha and reg_lambda add regularization terms to the loss function, penalizing large coefficients to simplify the model and prevent overfitting.\n",
    "Bayesian Optimization will iteratively explore this space, evaluating the model's performance at each iteration and using the results to update its understanding of the search space. This approach focuses on promising areas, efficiently finding a good set of hyperparameters. Libraries like Optuna or Hyperopt can be used to implement Bayesian Optimization, where you define an objective function that takes hyperparameters from the search space and returns a model performance metric to maximize or minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1fde7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "057c626c",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80d5913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfbd26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37ed5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the search space using trial.suggest_ methods\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n",
    "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-5, 1e-2),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1.0),\n",
    "        'random_state': 42,\n",
    "        'class_weight': 'balanced'  # Address class imbalance\n",
    "    }\n",
    "    \n",
    "    # Create and fit the model\n",
    "    model = lgb.LGBMClassifier(**param)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "    \n",
    "    # Predict and calculate ROC AUC Score\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2944a217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-19 19:37:35,125] A new study created in memory with name: no-name-1d53e6a6-2713-4d46-8772-67dcfc175aa3\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f59ec83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-19 19:37:36,658] Trial 0 finished with value: 0.7390188847603507 and parameters: {'num_leaves': 99, 'max_depth': 4, 'learning_rate': 0.20557838676208992, 'n_estimators': 319, 'min_child_samples': 487, 'min_child_weight': 0.003672268149442384, 'subsample': 0.6077675293079097, 'colsample_bytree': 0.7093308744545453, 'reg_alpha': 0.15439868866881978, 'reg_lambda': 0.42825937049353113}. Best is trial 0 with value: 0.7390188847603507.\n",
      "[I 2024-08-19 19:37:36,971] Trial 1 finished with value: 0.7389415762583863 and parameters: {'num_leaves': 66, 'max_depth': 3, 'learning_rate': 0.05832269875659352, 'n_estimators': 107, 'min_child_samples': 162, 'min_child_weight': 0.006527611161391073, 'subsample': 0.5249561735871834, 'colsample_bytree': 0.6950936901058258, 'reg_alpha': 0.9939718122134042, 'reg_lambda': 0.6575415212772678}. Best is trial 0 with value: 0.7390188847603507.\n",
      "[I 2024-08-19 19:37:37,489] Trial 2 finished with value: 0.7404723366611544 and parameters: {'num_leaves': 62, 'max_depth': 3, 'learning_rate': 0.20955707817935293, 'n_estimators': 196, 'min_child_samples': 126, 'min_child_weight': 1.9801774612734106e-05, 'subsample': 0.8301282480705694, 'colsample_bytree': 0.9673623862305591, 'reg_alpha': 0.18525783715858257, 'reg_lambda': 0.5009385554518238}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:40,224] Trial 3 finished with value: 0.7378424126632344 and parameters: {'num_leaves': 99, 'max_depth': 3, 'learning_rate': 0.20901290823951602, 'n_estimators': 758, 'min_child_samples': 419, 'min_child_weight': 6.0964810125814374e-05, 'subsample': 0.9853829837604163, 'colsample_bytree': 0.659134034539083, 'reg_alpha': 0.32736275298064665, 'reg_lambda': 0.8072064675903401}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:43,554] Trial 4 finished with value: 0.7363657732912434 and parameters: {'num_leaves': 65, 'max_depth': 5, 'learning_rate': 0.14407956144195863, 'n_estimators': 905, 'min_child_samples': 382, 'min_child_weight': 0.0006687239559014833, 'subsample': 0.7978467016022833, 'colsample_bytree': 0.532121777832888, 'reg_alpha': 0.5490075779302735, 'reg_lambda': 0.6865269382870166}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:46,021] Trial 5 finished with value: 0.7306525949954885 and parameters: {'num_leaves': 41, 'max_depth': 7, 'learning_rate': 0.2695719823901506, 'n_estimators': 602, 'min_child_samples': 281, 'min_child_weight': 0.0022215446551556678, 'subsample': 0.7679756779208347, 'colsample_bytree': 0.6415257400113205, 'reg_alpha': 0.9287790826569872, 'reg_lambda': 0.9479038646218874}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:48,640] Trial 6 finished with value: 0.7331933056424641 and parameters: {'num_leaves': 25, 'max_depth': 8, 'learning_rate': 0.15363892349294012, 'n_estimators': 809, 'min_child_samples': 170, 'min_child_weight': 2.9316750745238903e-05, 'subsample': 0.9455064862249325, 'colsample_bytree': 0.6053297034203776, 'reg_alpha': 0.5190892049889064, 'reg_lambda': 0.8515048620002099}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:49,818] Trial 7 finished with value: 0.733690521977659 and parameters: {'num_leaves': 72, 'max_depth': 6, 'learning_rate': 0.18960076720524915, 'n_estimators': 379, 'min_child_samples': 58, 'min_child_weight': 0.0029557265795815213, 'subsample': 0.5793314561754686, 'colsample_bytree': 0.8675867391427521, 'reg_alpha': 0.7046897023506598, 'reg_lambda': 0.767439451033352}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:52,263] Trial 8 finished with value: 0.7353629913534352 and parameters: {'num_leaves': 76, 'max_depth': 4, 'learning_rate': 0.232462158998952, 'n_estimators': 836, 'min_child_samples': 199, 'min_child_weight': 0.0037195503159445534, 'subsample': 0.9679326279686334, 'colsample_bytree': 0.642694360864363, 'reg_alpha': 0.30901501362201955, 'reg_lambda': 0.5548163871070707}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:52,620] Trial 9 finished with value: 0.7399360279765349 and parameters: {'num_leaves': 73, 'max_depth': 4, 'learning_rate': 0.046192738165538955, 'n_estimators': 85, 'min_child_samples': 253, 'min_child_weight': 2.535188739736234e-05, 'subsample': 0.7230644399815449, 'colsample_bytree': 0.952162631145753, 'reg_alpha': 0.03339016841344178, 'reg_lambda': 0.4155012353572366}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:53,974] Trial 10 finished with value: 0.7233174619791504 and parameters: {'num_leaves': 47, 'max_depth': 10, 'learning_rate': 0.29446271342055075, 'n_estimators': 295, 'min_child_samples': 20, 'min_child_weight': 0.00015340407449085803, 'subsample': 0.8607612646366237, 'colsample_bytree': 0.995824587340993, 'reg_alpha': 0.24857239129187753, 'reg_lambda': 0.0895645876487503}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:54,505] Trial 11 finished with value: 0.7393919859020174 and parameters: {'num_leaves': 84, 'max_depth': 5, 'learning_rate': 0.027610351174778124, 'n_estimators': 116, 'min_child_samples': 302, 'min_child_weight': 1.6321081166237612e-05, 'subsample': 0.6777506955305654, 'colsample_bytree': 0.9988228579028864, 'reg_alpha': 0.008731642345081995, 'reg_lambda': 0.34335665149183275}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:54,795] Trial 12 finished with value: 0.7396195939160138 and parameters: {'num_leaves': 53, 'max_depth': 3, 'learning_rate': 0.10167611780319716, 'n_estimators': 95, 'min_child_samples': 108, 'min_child_weight': 1.1902006863558957e-05, 'subsample': 0.7150169904918714, 'colsample_bytree': 0.8660636041624491, 'reg_alpha': 0.09139479388872444, 'reg_lambda': 0.16554232694000592}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:55,501] Trial 13 finished with value: 0.7400281365867515 and parameters: {'num_leaves': 87, 'max_depth': 5, 'learning_rate': 0.1056112001885444, 'n_estimators': 246, 'min_child_samples': 247, 'min_child_weight': 7.201457539523738e-05, 'subsample': 0.8529171723175534, 'colsample_bytree': 0.8796119379549403, 'reg_alpha': 0.002452448057574025, 'reg_lambda': 0.27188052568360305}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:57,299] Trial 14 finished with value: 0.7368415608982739 and parameters: {'num_leaves': 87, 'max_depth': 6, 'learning_rate': 0.10837258671438717, 'n_estimators': 496, 'min_child_samples': 118, 'min_child_weight': 9.9078713560638e-05, 'subsample': 0.8607810154972876, 'colsample_bytree': 0.8214477068166751, 'reg_alpha': 0.19512094976718353, 'reg_lambda': 0.2389706804022037}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:58,025] Trial 15 finished with value: 0.7402327793534084 and parameters: {'num_leaves': 36, 'max_depth': 5, 'learning_rate': 0.09749352865516236, 'n_estimators': 253, 'min_child_samples': 240, 'min_child_weight': 0.00047063976423505536, 'subsample': 0.8702710336455514, 'colsample_bytree': 0.9136649587151581, 'reg_alpha': 0.37158053092021404, 'reg_lambda': 0.28287398030500965}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:37:59,643] Trial 16 finished with value: 0.7394158971880225 and parameters: {'num_leaves': 30, 'max_depth': 8, 'learning_rate': 0.07807973441028973, 'n_estimators': 463, 'min_child_samples': 348, 'min_child_weight': 0.00041414440495037534, 'subsample': 0.907286259394143, 'colsample_bytree': 0.7864850784754346, 'reg_alpha': 0.4458485694337698, 'reg_lambda': 0.0046270647174058155}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:38:00,226] Trial 17 finished with value: 0.7399478248882175 and parameters: {'num_leaves': 35, 'max_depth': 4, 'learning_rate': 0.17588580731920525, 'n_estimators': 228, 'min_child_samples': 206, 'min_child_weight': 0.0011161370913040202, 'subsample': 0.8059291018308673, 'colsample_bytree': 0.9278780802128569, 'reg_alpha': 0.3943430204205488, 'reg_lambda': 0.5445019983486072}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:38:02,976] Trial 18 finished with value: 0.7210879980531666 and parameters: {'num_leaves': 54, 'max_depth': 10, 'learning_rate': 0.24805981703218047, 'n_estimators': 617, 'min_child_samples': 102, 'min_child_weight': 0.00026964001801566467, 'subsample': 0.9083808670002449, 'colsample_bytree': 0.9300377401326458, 'reg_alpha': 0.617568831715307, 'reg_lambda': 0.45244382789211507}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:38:04,355] Trial 19 finished with value: 0.7364148022212835 and parameters: {'num_leaves': 41, 'max_depth': 7, 'learning_rate': 0.13532451849867075, 'n_estimators': 403, 'min_child_samples': 313, 'min_child_weight': 0.00018831323191856246, 'subsample': 0.6566507304349465, 'colsample_bytree': 0.7921186701633179, 'reg_alpha': 0.7481203646692272, 'reg_lambda': 0.301428177723135}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:38:04,882] Trial 20 finished with value: 0.7388006609419772 and parameters: {'num_leaves': 56, 'max_depth': 5, 'learning_rate': 0.1730949224446583, 'n_estimators': 192, 'min_child_samples': 227, 'min_child_weight': 0.001021467786417825, 'subsample': 0.8186363039563165, 'colsample_bytree': 0.9061981628466985, 'reg_alpha': 0.3737764206161194, 'reg_lambda': 0.5838312735963572}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:38:05,551] Trial 21 finished with value: 0.7395949207196741 and parameters: {'num_leaves': 89, 'max_depth': 5, 'learning_rate': 0.10344782974695038, 'n_estimators': 228, 'min_child_samples': 158, 'min_child_weight': 3.9743278127033186e-05, 'subsample': 0.8627110578400059, 'colsample_bytree': 0.8684026614202744, 'reg_alpha': 0.09447144372311712, 'reg_lambda': 0.20677847911942782}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:38:06,427] Trial 22 finished with value: 0.7403730660937914 and parameters: {'num_leaves': 23, 'max_depth': 6, 'learning_rate': 0.08427329854929998, 'n_estimators': 318, 'min_child_samples': 242, 'min_child_weight': 7.428738242867594e-05, 'subsample': 0.9070333020906265, 'colsample_bytree': 0.9603193657621877, 'reg_alpha': 0.2028070916307172, 'reg_lambda': 0.3122909404961608}. Best is trial 2 with value: 0.7404723366611544.\n",
      "[I 2024-08-19 19:38:07,362] Trial 23 finished with value: 0.7409436226479574 and parameters: {'num_leaves': 21, 'max_depth': 6, 'learning_rate': 0.07021757278995576, 'n_estimators': 355, 'min_child_samples': 139, 'min_child_weight': 0.0001145216110186665, 'subsample': 0.9301930107244868, 'colsample_bytree': 0.9685915223216187, 'reg_alpha': 0.2571414981325095, 'reg_lambda': 0.34009027845157025}. Best is trial 23 with value: 0.7409436226479574.\n",
      "[I 2024-08-19 19:38:08,524] Trial 24 finished with value: 0.7418894962330136 and parameters: {'num_leaves': 20, 'max_depth': 8, 'learning_rate': 0.02665178267592029, 'n_estimators': 370, 'min_child_samples': 51, 'min_child_weight': 4.96056099791858e-05, 'subsample': 0.9268528239990959, 'colsample_bytree': 0.9699757027264854, 'reg_alpha': 0.2530448808905445, 'reg_lambda': 0.3564681990235679}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:10,176] Trial 25 finished with value: 0.7393267536788587 and parameters: {'num_leaves': 27, 'max_depth': 9, 'learning_rate': 0.035303796749109384, 'n_estimators': 577, 'min_child_samples': 44, 'min_child_weight': 4.166632435174164e-05, 'subsample': 0.9427258650495655, 'colsample_bytree': 0.9649138001855706, 'reg_alpha': 0.2674643984430688, 'reg_lambda': 0.4006889768733045}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:11,372] Trial 26 finished with value: 0.7398053603541278 and parameters: {'num_leaves': 20, 'max_depth': 8, 'learning_rate': 0.07089876634031103, 'n_estimators': 409, 'min_child_samples': 78, 'min_child_weight': 1.920267178118147e-05, 'subsample': 0.9329680036272945, 'colsample_bytree': 0.8394047505309422, 'reg_alpha': 0.12359133121390736, 'reg_lambda': 0.5179218186796084}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:12,110] Trial 27 finished with value: 0.7393253187477282 and parameters: {'num_leaves': 32, 'max_depth': 9, 'learning_rate': 0.01010589417433019, 'n_estimators': 173, 'min_child_samples': 121, 'min_child_weight': 1.0515405095182044e-05, 'subsample': 0.7655945740042975, 'colsample_bytree': 0.9968831505995878, 'reg_alpha': 0.22995855669219467, 'reg_lambda': 0.14338136780166097}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:14,414] Trial 28 finished with value: 0.7410918650020856 and parameters: {'num_leaves': 62, 'max_depth': 7, 'learning_rate': 0.016736601321108116, 'n_estimators': 362, 'min_child_samples': 78, 'min_child_weight': 0.00012530687125706242, 'subsample': 0.9825261281673106, 'colsample_bytree': 0.7618013832043395, 'reg_alpha': 0.4303330298061061, 'reg_lambda': 0.6424860178372667}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:16,036] Trial 29 finished with value: 0.7411513448022172 and parameters: {'num_leaves': 47, 'max_depth': 7, 'learning_rate': 0.0167143991955122, 'n_estimators': 361, 'min_child_samples': 21, 'min_child_weight': 0.00013600029660105977, 'subsample': 0.9938031610341177, 'colsample_bytree': 0.730580589212441, 'reg_alpha': 0.4515566118847805, 'reg_lambda': 0.6465505512822733}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:17,921] Trial 30 finished with value: 0.7411159731149273 and parameters: {'num_leaves': 47, 'max_depth': 7, 'learning_rate': 0.015205346151349303, 'n_estimators': 447, 'min_child_samples': 21, 'min_child_weight': 0.0001326413473969319, 'subsample': 0.9909379160052324, 'colsample_bytree': 0.7567331467693867, 'reg_alpha': 0.45563686166406325, 'reg_lambda': 0.6374601560682274}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:20,158] Trial 31 finished with value: 0.7410737251868662 and parameters: {'num_leaves': 47, 'max_depth': 7, 'learning_rate': 0.01069913168676788, 'n_estimators': 460, 'min_child_samples': 21, 'min_child_weight': 0.00021759709510651152, 'subsample': 0.9889111748277075, 'colsample_bytree': 0.7274939438116479, 'reg_alpha': 0.45804185203136, 'reg_lambda': 0.6488527082372945}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:22,178] Trial 32 finished with value: 0.738166205507738 and parameters: {'num_leaves': 42, 'max_depth': 8, 'learning_rate': 0.048971666012607676, 'n_estimators': 521, 'min_child_samples': 76, 'min_child_weight': 0.00014208748368721536, 'subsample': 0.9908302027545075, 'colsample_bytree': 0.7565467349585655, 'reg_alpha': 0.5814823950324018, 'reg_lambda': 0.7157760290759749}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:23,806] Trial 33 finished with value: 0.7408851714267777 and parameters: {'num_leaves': 59, 'max_depth': 7, 'learning_rate': 0.027579938399315766, 'n_estimators': 327, 'min_child_samples': 61, 'min_child_weight': 4.6058276335921077e-05, 'subsample': 0.9620376833219166, 'colsample_bytree': 0.6877990117702601, 'reg_alpha': 0.6494907109629242, 'reg_lambda': 0.6045602079660475}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:25,806] Trial 34 finished with value: 0.739287781965237 and parameters: {'num_leaves': 49, 'max_depth': 9, 'learning_rate': 0.05277440223639862, 'n_estimators': 425, 'min_child_samples': 37, 'min_child_weight': 9.295545392917747e-05, 'subsample': 0.9961480201837595, 'colsample_bytree': 0.7479679844960322, 'reg_alpha': 0.45091790953847327, 'reg_lambda': 0.4671025021270534}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:28,731] Trial 35 finished with value: 0.740116867394484 and parameters: {'num_leaves': 62, 'max_depth': 7, 'learning_rate': 0.02802833531440293, 'n_estimators': 679, 'min_child_samples': 85, 'min_child_weight': 0.0003107361128014693, 'subsample': 0.8939775998897294, 'colsample_bytree': 0.578592236400375, 'reg_alpha': 0.5027879693712811, 'reg_lambda': 0.7343246238333465}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:31,348] Trial 36 finished with value: 0.7404997844809632 and parameters: {'num_leaves': 69, 'max_depth': 8, 'learning_rate': 0.015694051027223443, 'n_estimators': 541, 'min_child_samples': 497, 'min_child_weight': 5.6473066701299926e-05, 'subsample': 0.9644972873758189, 'colsample_bytree': 0.6803306775739614, 'reg_alpha': 0.32144381597657845, 'reg_lambda': 0.6340305864293949}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:34,878] Trial 37 finished with value: 0.7374622575017183 and parameters: {'num_leaves': 64, 'max_depth': 7, 'learning_rate': 0.05721088009266574, 'n_estimators': 973, 'min_child_samples': 465, 'min_child_weight': 0.009588286569847275, 'subsample': 0.999810923302086, 'colsample_bytree': 0.7186485889228198, 'reg_alpha': 0.7872684232377863, 'reg_lambda': 0.8529594281277216}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:37,905] Trial 38 finished with value: 0.7371903063062405 and parameters: {'num_leaves': 51, 'max_depth': 9, 'learning_rate': 0.04208186548622175, 'n_estimators': 672, 'min_child_samples': 49, 'min_child_weight': 0.00012552141520859997, 'subsample': 0.9624020768019413, 'colsample_bytree': 0.7827918664006858, 'reg_alpha': 0.5566860223901222, 'reg_lambda': 0.9578313855780543}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:39,529] Trial 39 finished with value: 0.7412066023492437 and parameters: {'num_leaves': 44, 'max_depth': 8, 'learning_rate': 0.023966095549844364, 'n_estimators': 363, 'min_child_samples': 95, 'min_child_weight': 3.088475284214163e-05, 'subsample': 0.5255644639501895, 'colsample_bytree': 0.6013775011300041, 'reg_alpha': 0.3911134970949468, 'reg_lambda': 0.7828074699231944}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:41,699] Trial 40 finished with value: 0.7363627891424325 and parameters: {'num_leaves': 44, 'max_depth': 8, 'learning_rate': 0.13099273581249898, 'n_estimators': 452, 'min_child_samples': 154, 'min_child_weight': 3.0477075385498913e-05, 'subsample': 0.5606194224561323, 'colsample_bytree': 0.5150651961379815, 'reg_alpha': 0.3405881397794746, 'reg_lambda': 0.8866768178465166}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:43,605] Trial 41 finished with value: 0.7411093508442678 and parameters: {'num_leaves': 58, 'max_depth': 8, 'learning_rate': 0.024809320722973562, 'n_estimators': 372, 'min_child_samples': 92, 'min_child_weight': 6.383418949162557e-05, 'subsample': 0.532718301108935, 'colsample_bytree': 0.5968293966680016, 'reg_alpha': 0.4148000730282609, 'reg_lambda': 0.6780012748441329}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:44,793] Trial 42 finished with value: 0.7411416113976911 and parameters: {'num_leaves': 38, 'max_depth': 8, 'learning_rate': 0.04011317032635979, 'n_estimators': 285, 'min_child_samples': 21, 'min_child_weight': 6.245167640844269e-05, 'subsample': 0.522609543913632, 'colsample_bytree': 0.5635357091868933, 'reg_alpha': 0.5064721480930382, 'reg_lambda': 0.8170123566198566}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:45,967] Trial 43 finished with value: 0.7403530786460101 and parameters: {'num_leaves': 37, 'max_depth': 9, 'learning_rate': 0.06323102609896894, 'n_estimators': 299, 'min_child_samples': 23, 'min_child_weight': 2.580711301417002e-05, 'subsample': 0.5091832574376524, 'colsample_bytree': 0.557544009769841, 'reg_alpha': 0.5423053342195913, 'reg_lambda': 0.7835643684467579}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:47,141] Trial 44 finished with value: 0.741240704185976 and parameters: {'num_leaves': 39, 'max_depth': 8, 'learning_rate': 0.0374587920110781, 'n_estimators': 293, 'min_child_samples': 58, 'min_child_weight': 4.8873961574042035e-05, 'subsample': 0.6035718447425574, 'colsample_bytree': 0.6308177800036077, 'reg_alpha': 0.4914385912755664, 'reg_lambda': 0.9085229468233498}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:48,088] Trial 45 finished with value: 0.7414971505061421 and parameters: {'num_leaves': 39, 'max_depth': 8, 'learning_rate': 0.04185787714728327, 'n_estimators': 162, 'min_child_samples': 64, 'min_child_weight': 3.527248728156954e-05, 'subsample': 0.6261185499465209, 'colsample_bytree': 0.628467670359413, 'reg_alpha': 0.4877644165369812, 'reg_lambda': 0.9125707116267907}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:48,672] Trial 46 finished with value: 0.7416495452715947 and parameters: {'num_leaves': 34, 'max_depth': 9, 'learning_rate': 0.08684931273952692, 'n_estimators': 141, 'min_child_samples': 62, 'min_child_weight': 1.6796113992651804e-05, 'subsample': 0.6186529113001429, 'colsample_bytree': 0.6329003919122242, 'reg_alpha': 0.30042872567634676, 'reg_lambda': 0.912417212859393}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:49,255] Trial 47 finished with value: 0.7406436141044028 and parameters: {'num_leaves': 29, 'max_depth': 10, 'learning_rate': 0.08240591443679879, 'n_estimators': 154, 'min_child_samples': 65, 'min_child_weight': 1.4052523513382755e-05, 'subsample': 0.6258937076742577, 'colsample_bytree': 0.6272908909489515, 'reg_alpha': 0.29536968933797203, 'reg_lambda': 0.9914078225404649}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:49,781] Trial 48 finished with value: 0.741547696907599 and parameters: {'num_leaves': 33, 'max_depth': 9, 'learning_rate': 0.054251872350706956, 'n_estimators': 128, 'min_child_samples': 129, 'min_child_weight': 2.0082111263521676e-05, 'subsample': 0.5953792486486563, 'colsample_bytree': 0.6624024468137971, 'reg_alpha': 0.14461961873558224, 'reg_lambda': 0.8813070130556994}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:50,038] Trial 49 finished with value: 0.7404436380385462 and parameters: {'num_leaves': 33, 'max_depth': 9, 'learning_rate': 0.08877558902526986, 'n_estimators': 51, 'min_child_samples': 189, 'min_child_weight': 1.8801221603841677e-05, 'subsample': 0.5893622047595919, 'colsample_bytree': 0.6408864140951519, 'reg_alpha': 0.15450056530187495, 'reg_lambda': 0.8976068769738147}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:50,610] Trial 50 finished with value: 0.7399869299361478 and parameters: {'num_leaves': 26, 'max_depth': 10, 'learning_rate': 0.11834168469157358, 'n_estimators': 161, 'min_child_samples': 139, 'min_child_weight': 1.4833909584094823e-05, 'subsample': 0.6291319224523416, 'colsample_bytree': 0.666291434273794, 'reg_alpha': 0.15311494340560283, 'reg_lambda': 0.9238582069973073}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:51,182] Trial 51 finished with value: 0.74119143398433 and parameters: {'num_leaves': 38, 'max_depth': 9, 'learning_rate': 0.03715950823875483, 'n_estimators': 123, 'min_child_samples': 101, 'min_child_weight': 3.4402688409189076e-05, 'subsample': 0.6788844497670874, 'colsample_bytree': 0.6091962733132887, 'reg_alpha': 0.35790337502607616, 'reg_lambda': 0.8431516634217202}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:51,456] Trial 52 finished with value: 0.7404580825886422 and parameters: {'num_leaves': 32, 'max_depth': 8, 'learning_rate': 0.06110226841080987, 'n_estimators': 58, 'min_child_samples': 56, 'min_child_weight': 2.2678606939049907e-05, 'subsample': 0.5519199456317117, 'colsample_bytree': 0.6195724685675463, 'reg_alpha': 0.06216814541878368, 'reg_lambda': 0.9966836263626254}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:52,468] Trial 53 finished with value: 0.7405168068276918 and parameters: {'num_leaves': 41, 'max_depth': 9, 'learning_rate': 0.053893975536573116, 'n_estimators': 266, 'min_child_samples': 120, 'min_child_weight': 2.8900865239526478e-05, 'subsample': 0.5999610812855122, 'colsample_bytree': 0.6544312242447696, 'reg_alpha': 0.29180818086101157, 'reg_lambda': 0.879984456764271}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:53,450] Trial 54 finished with value: 0.7414264261793204 and parameters: {'num_leaves': 29, 'max_depth': 8, 'learning_rate': 0.06770800011811487, 'n_estimators': 220, 'min_child_samples': 137, 'min_child_weight': 1.2967557042020532e-05, 'subsample': 0.6260051844753074, 'colsample_bytree': 0.5911823909979588, 'reg_alpha': 0.39301719088848286, 'reg_lambda': 0.9539471605567565}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:54,168] Trial 55 finished with value: 0.7409429305794033 and parameters: {'num_leaves': 23, 'max_depth': 9, 'learning_rate': 0.07047221173596037, 'n_estimators': 214, 'min_child_samples': 182, 'min_child_weight': 1.1896887776983965e-05, 'subsample': 0.6203237743183329, 'colsample_bytree': 0.5498574520096151, 'reg_alpha': 0.22781768927631582, 'reg_lambda': 0.9355469023513464}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:54,641] Trial 56 finished with value: 0.7411423288632562 and parameters: {'num_leaves': 29, 'max_depth': 10, 'learning_rate': 0.04566315618207048, 'n_estimators': 117, 'min_child_samples': 68, 'min_child_weight': 1.9547154905453893e-05, 'subsample': 0.6622185257976819, 'colsample_bytree': 0.7009609225294862, 'reg_alpha': 0.18001621393184009, 'reg_lambda': 0.9419584193871363}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:55,141] Trial 57 finished with value: 0.7384916999519896 and parameters: {'num_leaves': 25, 'max_depth': 8, 'learning_rate': 0.21915653157276993, 'n_estimators': 145, 'min_child_samples': 137, 'min_child_weight': 1.0025031648860304e-05, 'subsample': 0.6450239087412293, 'colsample_bytree': 0.67019193492288, 'reg_alpha': 0.6221809074752311, 'reg_lambda': 0.8414540122742133}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:55,901] Trial 58 finished with value: 0.7400633304949633 and parameters: {'num_leaves': 35, 'max_depth': 9, 'learning_rate': 0.09126733321479397, 'n_estimators': 197, 'min_child_samples': 215, 'min_child_weight': 4.578099386360008e-05, 'subsample': 0.6973463408446975, 'colsample_bytree': 0.5872149985210676, 'reg_alpha': 0.27557934605607126, 'reg_lambda': 0.9747617489806419}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:56,755] Trial 59 finished with value: 0.739047710368015 and parameters: {'num_leaves': 28, 'max_depth': 10, 'learning_rate': 0.11358203434911979, 'n_estimators': 247, 'min_child_samples': 273, 'min_child_weight': 1.4699336619109255e-05, 'subsample': 0.5759344884801987, 'colsample_bytree': 0.6379422106293228, 'reg_alpha': 0.9895057710623787, 'reg_lambda': 0.9140334192012328}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:57,395] Trial 60 finished with value: 0.7410150263448276 and parameters: {'num_leaves': 23, 'max_depth': 8, 'learning_rate': 0.07302012301488499, 'n_estimators': 180, 'min_child_samples': 42, 'min_child_weight': 2.2383732062807976e-05, 'subsample': 0.6088180134234447, 'colsample_bytree': 0.5030946632083271, 'reg_alpha': 0.48451165898759396, 'reg_lambda': 0.3941600044389822}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:58,690] Trial 61 finished with value: 0.7412184246579377 and parameters: {'num_leaves': 44, 'max_depth': 8, 'learning_rate': 0.03295201574465544, 'n_estimators': 280, 'min_child_samples': 103, 'min_child_weight': 3.6172159552108184e-05, 'subsample': 0.5650813869660649, 'colsample_bytree': 0.5381695104757482, 'reg_alpha': 0.3925504785824329, 'reg_lambda': 0.7859180980752388}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:38:59,248] Trial 62 finished with value: 0.7400688289478791 and parameters: {'num_leaves': 40, 'max_depth': 8, 'learning_rate': 0.03412355167832761, 'n_estimators': 84, 'min_child_samples': 109, 'min_child_weight': 3.652204155378092e-05, 'subsample': 0.5649962154989636, 'colsample_bytree': 0.5381114826888418, 'reg_alpha': 0.3234540174078841, 'reg_lambda': 0.8590345651356671}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:00,124] Trial 63 finished with value: 0.741060493344053 and parameters: {'num_leaves': 33, 'max_depth': 9, 'learning_rate': 0.048317376852317725, 'n_estimators': 220, 'min_child_samples': 157, 'min_child_weight': 5.34730465157002e-05, 'subsample': 0.5905521263542589, 'colsample_bytree': 0.584829544069795, 'reg_alpha': 0.396138166788892, 'reg_lambda': 0.8087267557794894}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:01,179] Trial 64 finished with value: 0.7403671739872028 and parameters: {'num_leaves': 30, 'max_depth': 8, 'learning_rate': 0.06329742356955309, 'n_estimators': 318, 'min_child_samples': 132, 'min_child_weight': 1.663935388843032e-05, 'subsample': 0.7444696762263194, 'colsample_bytree': 0.6237771598293723, 'reg_alpha': 0.35345808016938046, 'reg_lambda': 0.7454189709393665}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:02,175] Trial 65 finished with value: 0.7399820410115 and parameters: {'num_leaves': 35, 'max_depth': 9, 'learning_rate': 0.07975558584046599, 'n_estimators': 270, 'min_child_samples': 85, 'min_child_weight': 2.7161465667805812e-05, 'subsample': 0.6371553456910836, 'colsample_bytree': 0.5698050985714026, 'reg_alpha': 0.21074363915685074, 'reg_lambda': 0.9597633435739734}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:02,606] Trial 66 finished with value: 0.7391452348908609 and parameters: {'num_leaves': 39, 'max_depth': 8, 'learning_rate': 0.027439105680690547, 'n_estimators': 89, 'min_child_samples': 38, 'min_child_weight': 8.679548520412601e-05, 'subsample': 0.541073867393284, 'colsample_bytree': 0.529936281513769, 'reg_alpha': 0.47650015573731574, 'reg_lambda': 0.9064875244200171}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:03,349] Trial 67 finished with value: 0.7414298166803098 and parameters: {'num_leaves': 31, 'max_depth': 6, 'learning_rate': 0.0354085033335932, 'n_estimators': 205, 'min_child_samples': 176, 'min_child_weight': 4.488395945574255e-05, 'subsample': 0.6124827084914077, 'colsample_bytree': 0.6124305930112657, 'reg_alpha': 0.4162221998332048, 'reg_lambda': 0.876745349819961}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:03,786] Trial 68 finished with value: 0.7409292796859059 and parameters: {'num_leaves': 21, 'max_depth': 6, 'learning_rate': 0.09262383008369848, 'n_estimators': 132, 'min_child_samples': 173, 'min_child_weight': 4.929191832128377e-05, 'subsample': 0.6119310953513126, 'colsample_bytree': 0.6493579135088126, 'reg_alpha': 0.4250286121861117, 'reg_lambda': 0.9298426186204589}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:04,626] Trial 69 finished with value: 0.7387752258353026 and parameters: {'num_leaves': 26, 'max_depth': 6, 'learning_rate': 0.16104922757742074, 'n_estimators': 196, 'min_child_samples': 115, 'min_child_weight': 1.2868660839853892e-05, 'subsample': 0.655268879813822, 'colsample_bytree': 0.6134876019362586, 'reg_alpha': 0.515056836824639, 'reg_lambda': 0.8176282247817375}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:05,558] Trial 70 finished with value: 0.7404146346518039 and parameters: {'num_leaves': 31, 'max_depth': 7, 'learning_rate': 0.06335262561510308, 'n_estimators': 239, 'min_child_samples': 149, 'min_child_weight': 7.925527393818045e-05, 'subsample': 0.6896246145949486, 'colsample_bytree': 0.6801874360165876, 'reg_alpha': 0.2472650904542211, 'reg_lambda': 0.8791111055119905}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:06,663] Trial 71 finished with value: 0.7414208642338767 and parameters: {'num_leaves': 35, 'max_depth': 6, 'learning_rate': 0.03858312818563871, 'n_estimators': 329, 'min_child_samples': 69, 'min_child_weight': 3.836755136392902e-05, 'subsample': 0.5748305295077617, 'colsample_bytree': 0.6328494465250867, 'reg_alpha': 0.381853831688998, 'reg_lambda': 0.8679257980665434}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:07,790] Trial 72 finished with value: 0.7407698626468684 and parameters: {'num_leaves': 34, 'max_depth': 6, 'learning_rate': 0.04357465188438024, 'n_estimators': 326, 'min_child_samples': 72, 'min_child_weight': 2.192623630070607e-05, 'subsample': 0.5847603081289414, 'colsample_bytree': 0.6301218275364402, 'reg_alpha': 0.3126976825232, 'reg_lambda': 0.9733552705064403}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:08,329] Trial 73 finished with value: 0.7417010313624643 and parameters: {'num_leaves': 95, 'max_depth': 5, 'learning_rate': 0.05252317606806772, 'n_estimators': 155, 'min_child_samples': 62, 'min_child_weight': 4.037886699024774e-05, 'subsample': 0.6034143465490145, 'colsample_bytree': 0.6627406273308356, 'reg_alpha': 0.5433494549998865, 'reg_lambda': 0.8725717462367801}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:08,901] Trial 74 finished with value: 0.7415756590168836 and parameters: {'num_leaves': 100, 'max_depth': 5, 'learning_rate': 0.05095621668990653, 'n_estimators': 170, 'min_child_samples': 91, 'min_child_weight': 1.6558625594437872e-05, 'subsample': 0.6380308406077035, 'colsample_bytree': 0.6655547208094481, 'reg_alpha': 0.5838975074527017, 'reg_lambda': 0.8697883252680862}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:09,283] Trial 75 finished with value: 0.7409951150880799 and parameters: {'num_leaves': 98, 'max_depth': 5, 'learning_rate': 0.051595665356584, 'n_estimators': 100, 'min_child_samples': 92, 'min_child_weight': 1.74919735120435e-05, 'subsample': 0.7102559958823925, 'colsample_bytree': 0.6652003025573422, 'reg_alpha': 0.6990675894540905, 'reg_lambda': 0.36902241189836393}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:09,722] Trial 76 finished with value: 0.7410300804231915 and parameters: {'num_leaves': 96, 'max_depth': 4, 'learning_rate': 0.07666359694744103, 'n_estimators': 167, 'min_child_samples': 372, 'min_child_weight': 1.1959614494417956e-05, 'subsample': 0.6452249014947986, 'colsample_bytree': 0.7038506410281223, 'reg_alpha': 0.5698608530353477, 'reg_lambda': 0.8384601419928824}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:10,376] Trial 77 finished with value: 0.7412908950292766 and parameters: {'num_leaves': 79, 'max_depth': 5, 'learning_rate': 0.05660342250730031, 'n_estimators': 141, 'min_child_samples': 49, 'min_child_weight': 2.1775034671802326e-05, 'subsample': 0.6641516216729867, 'colsample_bytree': 0.6524524497496544, 'reg_alpha': 0.5931035120583379, 'reg_lambda': 0.6955588170316038}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:10,722] Trial 78 finished with value: 0.7376389762546072 and parameters: {'num_leaves': 92, 'max_depth': 5, 'learning_rate': 0.01814212782868706, 'n_estimators': 69, 'min_child_samples': 121, 'min_child_weight': 1.6321172955910324e-05, 'subsample': 0.6211321897083163, 'colsample_bytree': 0.8220572915903016, 'reg_alpha': 0.6644745086164849, 'reg_lambda': 0.03159697295381425}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:11,324] Trial 79 finished with value: 0.7399518947592556 and parameters: {'num_leaves': 93, 'max_depth': 4, 'learning_rate': 0.1922036574313927, 'n_estimators': 206, 'min_child_samples': 167, 'min_child_weight': 0.0021989783352278037, 'subsample': 0.6713194471301263, 'colsample_bytree': 0.5979558917907347, 'reg_alpha': 0.5297289799865015, 'reg_lambda': 0.7514462499822677}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:11,735] Trial 80 finished with value: 0.7407154178041989 and parameters: {'num_leaves': 77, 'max_depth': 5, 'learning_rate': 0.07014673316884715, 'n_estimators': 111, 'min_child_samples': 81, 'min_child_weight': 2.5009160494924636e-05, 'subsample': 0.7834137154102414, 'colsample_bytree': 0.6850062091984906, 'reg_alpha': 0.1023323015688059, 'reg_lambda': 0.9512473914004621}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:12,409] Trial 81 finished with value: 0.7340938836581206 and parameters: {'num_leaves': 100, 'max_depth': 6, 'learning_rate': 0.29943491490590013, 'n_estimators': 181, 'min_child_samples': 34, 'min_child_weight': 2.7516982785531164e-05, 'subsample': 0.6015370521002674, 'colsample_bytree': 0.6138240958155621, 'reg_alpha': 0.421997301516327, 'reg_lambda': 0.8807672506347305}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:12,953] Trial 82 finished with value: 0.7397133406334502 and parameters: {'num_leaves': 95, 'max_depth': 3, 'learning_rate': 0.04307020809151034, 'n_estimators': 233, 'min_child_samples': 67, 'min_child_weight': 4.0730892884982095e-05, 'subsample': 0.8430876105204816, 'colsample_bytree': 0.6723552324777509, 'reg_alpha': 0.4693844970824268, 'reg_lambda': 0.8629779919527287}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:13,600] Trial 83 finished with value: 0.7406538681476578 and parameters: {'num_leaves': 82, 'max_depth': 6, 'learning_rate': 0.02053402403213596, 'n_estimators': 154, 'min_child_samples': 52, 'min_child_weight': 6.698088215655248e-05, 'subsample': 0.5739329973157429, 'colsample_bytree': 0.7149268319750925, 'reg_alpha': 0.3829955752711037, 'reg_lambda': 0.8197012738043771}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:14,747] Trial 84 finished with value: 0.7412597201980805 and parameters: {'num_leaves': 24, 'max_depth': 5, 'learning_rate': 0.030833985056873667, 'n_estimators': 389, 'min_child_samples': 93, 'min_child_weight': 3.102535073397529e-05, 'subsample': 0.6378346423449457, 'colsample_bytree': 0.6396999845413568, 'reg_alpha': 0.34962331676887926, 'reg_lambda': 0.25179804749227597}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:16,476] Trial 85 finished with value: 0.7391015139361528 and parameters: {'num_leaves': 36, 'max_depth': 6, 'learning_rate': 0.05727423643625054, 'n_estimators': 489, 'min_child_samples': 109, 'min_child_weight': 3.896740973007341e-05, 'subsample': 0.596724289086596, 'colsample_bytree': 0.6947382628667234, 'reg_alpha': 0.5396300995609308, 'reg_lambda': 0.9012962851731877}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:16,972] Trial 86 finished with value: 0.7418248862366281 and parameters: {'num_leaves': 27, 'max_depth': 6, 'learning_rate': 0.06621310017589954, 'n_estimators': 133, 'min_child_samples': 146, 'min_child_weight': 1.1359452995339411e-05, 'subsample': 0.5426164756587009, 'colsample_bytree': 0.5750724360673631, 'reg_alpha': 0.05323443899701018, 'reg_lambda': 0.8684102195022718}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:17,370] Trial 87 finished with value: 0.7388213468075653 and parameters: {'num_leaves': 21, 'max_depth': 4, 'learning_rate': 0.2807963540601425, 'n_estimators': 130, 'min_child_samples': 197, 'min_child_weight': 1.1100138904477317e-05, 'subsample': 0.5525562377601476, 'colsample_bytree': 0.5908578071733849, 'reg_alpha': 0.05076957874060596, 'reg_lambda': 0.44381115664962284}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:17,739] Trial 88 finished with value: 0.7412157579717663 and parameters: {'num_leaves': 28, 'max_depth': 7, 'learning_rate': 0.09925958069475002, 'n_estimators': 89, 'min_child_samples': 148, 'min_child_weight': 1.3109184176922468e-05, 'subsample': 0.616708871221519, 'colsample_bytree': 0.578357249488453, 'reg_alpha': 0.03262804901952881, 'reg_lambda': 0.7923680722916457}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:18,358] Trial 89 finished with value: 0.7412849076838962 and parameters: {'num_leaves': 89, 'max_depth': 5, 'learning_rate': 0.06689722285593978, 'n_estimators': 181, 'min_child_samples': 129, 'min_child_weight': 0.000643865365561785, 'subsample': 0.5008241682894053, 'colsample_bytree': 0.60373198082665, 'reg_alpha': 0.1645116000580817, 'reg_lambda': 0.9310499021209719}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:19,146] Trial 90 finished with value: 0.7413267238627675 and parameters: {'num_leaves': 31, 'max_depth': 7, 'learning_rate': 0.050483968563927256, 'n_estimators': 217, 'min_child_samples': 83, 'min_child_weight': 1.7765994624801683e-05, 'subsample': 0.6322621728045276, 'colsample_bytree': 0.5694770141301339, 'reg_alpha': 0.12427876510958372, 'reg_lambda': 0.9763953696981688}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:19,977] Trial 91 finished with value: 0.7412852886390635 and parameters: {'num_leaves': 27, 'max_depth': 6, 'learning_rate': 0.03862369521764712, 'n_estimators': 253, 'min_child_samples': 67, 'min_child_weight': 1.4817853070102758e-05, 'subsample': 0.5830202365470221, 'colsample_bytree': 0.6577865363026254, 'reg_alpha': 0.44467409486015075, 'reg_lambda': 0.8673536547234312}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:20,550] Trial 92 finished with value: 0.740163007414505 and parameters: {'num_leaves': 33, 'max_depth': 6, 'learning_rate': 0.08587401086644769, 'n_estimators': 161, 'min_child_samples': 33, 'min_child_weight': 1.0088200701993045e-05, 'subsample': 0.6484631105912222, 'colsample_bytree': 0.6473690255214309, 'reg_alpha': 0.5967027352442045, 'reg_lambda': 0.8358190558165506}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:20,963] Trial 93 finished with value: 0.7408918127451953 and parameters: {'num_leaves': 70, 'max_depth': 5, 'learning_rate': 0.04625290273054593, 'n_estimators': 109, 'min_child_samples': 173, 'min_child_weight': 2.07320957870131e-05, 'subsample': 0.5506688216235608, 'colsample_bytree': 0.6201699204454071, 'reg_alpha': 0.2826345651355396, 'reg_lambda': 0.909762174512831}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:21,714] Trial 94 finished with value: 0.7413373842582011 and parameters: {'num_leaves': 98, 'max_depth': 6, 'learning_rate': 0.06106008655085406, 'n_estimators': 136, 'min_child_samples': 96, 'min_child_weight': 3.339157816547543e-05, 'subsample': 0.5769392639523219, 'colsample_bytree': 0.6068137811767892, 'reg_alpha': 0.41077241700679185, 'reg_lambda': 0.7683724921322006}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:22,395] Trial 95 finished with value: 0.741482407541165 and parameters: {'num_leaves': 20, 'max_depth': 5, 'learning_rate': 0.07711000913874579, 'n_estimators': 196, 'min_child_samples': 141, 'min_child_weight': 2.4251128067119462e-05, 'subsample': 0.5405805495263162, 'colsample_bytree': 0.5510739817438434, 'reg_alpha': 0.2187783164861239, 'reg_lambda': 0.8944738997665584}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:22,674] Trial 96 finished with value: 0.74050492102647 and parameters: {'num_leaves': 20, 'max_depth': 5, 'learning_rate': 0.074318344264364, 'n_estimators': 70, 'min_child_samples': 148, 'min_child_weight': 2.3902167166084014e-05, 'subsample': 0.5141657381948069, 'colsample_bytree': 0.5580052355795612, 'reg_alpha': 0.12126778070181152, 'reg_lambda': 0.4785870318226117}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:23,210] Trial 97 finished with value: 0.7410469694356114 and parameters: {'num_leaves': 25, 'max_depth': 5, 'learning_rate': 0.07807418852320731, 'n_estimators': 188, 'min_child_samples': 124, 'min_child_weight': 1.9207086033281747e-05, 'subsample': 0.5324101933668431, 'colsample_bytree': 0.9845449818202302, 'reg_alpha': 0.22174950632974005, 'reg_lambda': 0.999420632821442}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:23,928] Trial 98 finished with value: 0.7402407857611758 and parameters: {'num_leaves': 22, 'max_depth': 4, 'learning_rate': 0.12694308344944172, 'n_estimators': 208, 'min_child_samples': 182, 'min_child_weight': 0.00017764219778409159, 'subsample': 0.8822675175204131, 'colsample_bytree': 0.5503920814878338, 'reg_alpha': 0.25911907566102693, 'reg_lambda': 0.8915480110772223}. Best is trial 24 with value: 0.7418894962330136.\n",
      "[I 2024-08-19 19:39:24,495] Trial 99 finished with value: 0.740963870415103 and parameters: {'num_leaves': 29, 'max_depth': 10, 'learning_rate': 0.09402412359365689, 'n_estimators': 165, 'min_child_samples': 143, 'min_child_weight': 1.5255292970859744e-05, 'subsample': 0.6085421416918088, 'colsample_bytree': 0.7351979370800963, 'reg_alpha': 0.5598694024605102, 'reg_lambda': 0.19698932025628668}. Best is trial 24 with value: 0.7418894962330136.\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cbc933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial: {'num_leaves': 20, 'max_depth': 8, 'learning_rate': 0.02665178267592029, 'n_estimators': 370, 'min_child_samples': 51, 'min_child_weight': 4.96056099791858e-05, 'subsample': 0.9268528239990959, 'colsample_bytree': 0.9699757027264854, 'reg_alpha': 0.2530448808905445, 'reg_lambda': 0.3564681990235679}\n"
     ]
    }
   ],
   "source": [
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49b437a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ea78b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 20,\n",
       " 'max_depth': 8,\n",
       " 'learning_rate': 0.02665178267592029,\n",
       " 'n_estimators': 370,\n",
       " 'min_child_samples': 51,\n",
       " 'min_child_weight': 4.96056099791858e-05,\n",
       " 'subsample': 0.9268528239990959,\n",
       " 'colsample_bytree': 0.9699757027264854,\n",
       " 'reg_alpha': 0.2530448808905445,\n",
       " 'reg_lambda': 0.3564681990235679}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c91e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"random_state\"] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3667fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"class_weight\"] = \"balanced\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "458142a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 20,\n",
       " 'max_depth': 8,\n",
       " 'learning_rate': 0.02665178267592029,\n",
       " 'n_estimators': 370,\n",
       " 'min_child_samples': 51,\n",
       " 'min_child_weight': 4.96056099791858e-05,\n",
       " 'subsample': 0.9268528239990959,\n",
       " 'colsample_bytree': 0.9699757027264854,\n",
       " 'reg_alpha': 0.2530448808905445,\n",
       " 'reg_lambda': 0.3564681990235679,\n",
       " 'random_state': 42,\n",
       " 'class_weight': 'balanced'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17fd8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_classifier = lgb.LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a40a635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.9699757027264854,\n",
       "               learning_rate=0.02665178267592029, max_depth=8,\n",
       "               min_child_samples=51, min_child_weight=4.96056099791858e-05,\n",
       "               n_estimators=370, num_leaves=20, random_state=42,\n",
       "               reg_alpha=0.2530448808905445, reg_lambda=0.3564681990235679,\n",
       "               subsample=0.9268528239990959)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.9699757027264854,\n",
       "               learning_rate=0.02665178267592029, max_depth=8,\n",
       "               min_child_samples=51, min_child_weight=4.96056099791858e-05,\n",
       "               n_estimators=370, num_leaves=20, random_state=42,\n",
       "               reg_alpha=0.2530448808905445, reg_lambda=0.3564681990235679,\n",
       "               subsample=0.9268528239990959)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', colsample_bytree=0.9699757027264854,\n",
       "               learning_rate=0.02665178267592029, max_depth=8,\n",
       "               min_child_samples=51, min_child_weight=4.96056099791858e-05,\n",
       "               n_estimators=370, num_leaves=20, random_state=42,\n",
       "               reg_alpha=0.2530448808905445, reg_lambda=0.3564681990235679,\n",
       "               subsample=0.9268528239990959)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6bccdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.9699757027264854,\n",
       "               learning_rate=0.02665178267592029, max_depth=8,\n",
       "               min_child_samples=51, min_child_weight=4.96056099791858e-05,\n",
       "               n_estimators=370, num_leaves=20, random_state=42,\n",
       "               reg_alpha=0.2530448808905445, reg_lambda=0.3564681990235679,\n",
       "               subsample=0.9268528239990959)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.9699757027264854,\n",
       "               learning_rate=0.02665178267592029, max_depth=8,\n",
       "               min_child_samples=51, min_child_weight=4.96056099791858e-05,\n",
       "               n_estimators=370, num_leaves=20, random_state=42,\n",
       "               reg_alpha=0.2530448808905445, reg_lambda=0.3564681990235679,\n",
       "               subsample=0.9268528239990959)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', colsample_bytree=0.9699757027264854,\n",
       "               learning_rate=0.02665178267592029, max_depth=8,\n",
       "               min_child_samples=51, min_child_weight=4.96056099791858e-05,\n",
       "               n_estimators=370, num_leaves=20, random_state=42,\n",
       "               reg_alpha=0.2530448808905445, reg_lambda=0.3564681990235679,\n",
       "               subsample=0.9268528239990959)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ce62bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8519aece",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = lgbm_classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "001a0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cb14d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5967428183668854\n",
      "Precision: 0.31274196263255344\n",
      "Recall: 0.8324372759856631\n",
      "F1 Score: 0.454667808638199\n",
      "ROC AUC Score: 0.7418894962330136\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37add3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c69533ea",
   "metadata": {},
   "source": [
    "Let's consider the following business case: Hospitals may introduce overbooking (2 patients for the same slot) for appointments with a high likelihood of a no-show. Precision should be 75% or higher while keeping up the recall as high as possible.Â Please provide the corresponding code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07e11c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c791562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming model is your optimized LightGBM model and X_test is your test set\n",
    "y_pred_proba = lgbm_classifier.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "674f2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision-recall pairs for different probability thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7c28ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the threshold that is closest to your desired precision\n",
    "target_precision = 0.75\n",
    "closest_precision_idx = np.argmin(np.abs(precision - target_precision))\n",
    "selected_threshold = thresholds[closest_precision_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe57c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the threshold based on your precision requirement\n",
    "y_pred_adjusted = (y_pred_proba >= selected_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "705269ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate metrics\n",
    "adjusted_precision = precision_score(y_test, y_pred_adjusted)\n",
    "adjusted_recall = recall_score(y_test, y_pred_adjusted)\n",
    "adjusted_accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "adjusted_f1 = f1_score(y_test, y_pred_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "490b0e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Threshold: 0.8524304906735681\n",
      "Adjusted Accuracy: 0.8005881022393124\n",
      "Adjusted Precision: 0.75\n",
      "Adjusted Recall: 0.01881720430107527\n",
      "Adjusted F1 Score: 0.03671328671328672\n"
     ]
    }
   ],
   "source": [
    "# Print the new metrics and selected threshold\n",
    "print(f\"Selected Threshold: {selected_threshold}\")\n",
    "print(f\"Adjusted Accuracy: {adjusted_accuracy}\")\n",
    "print(f\"Adjusted Precision: {adjusted_precision}\")\n",
    "print(f\"Adjusted Recall: {adjusted_recall}\")\n",
    "print(f\"Adjusted F1 Score: {adjusted_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a8d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81154cb1",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ef19d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77e2522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming lgbm_classifier is your trained LightGBM model\n",
    "feature_importances = lgbm_classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf378e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 308, 2546,  253,  153,  111,   99,  152,  118, 1729,  404,  653,\n",
       "        122,   43,  339], dtype=int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5c04e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train is your features DataFrame\n",
    "feature_names = X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba1fd244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SMSreceived', 'Age', 'GenderM', 'Scholarship', 'Hipertension',\n",
       "       'Diabetes', 'Alcoholism', 'Handcap', 'TimeGapDays', 'prevNoshow',\n",
       "       'WeekDay', 'AgeCategory', 'WaitingTimeCategory', 'TotalConditions'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f2fb345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to hold the feature names and their importance scores\n",
    "feature_importance_df = pd.DataFrame({'Feature Name': feature_names, 'Importance': feature_importances})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e077ff6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMSreceived</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>2546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GenderM</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scholarship</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hipertension</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alcoholism</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Handcap</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeGapDays</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prevNoshow</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeekDay</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AgeCategory</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WaitingTimeCategory</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TotalConditions</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Name  Importance\n",
       "0           SMSreceived         308\n",
       "1                   Age        2546\n",
       "2               GenderM         253\n",
       "3           Scholarship         153\n",
       "4          Hipertension         111\n",
       "5              Diabetes          99\n",
       "6            Alcoholism         152\n",
       "7               Handcap         118\n",
       "8           TimeGapDays        1729\n",
       "9            prevNoshow         404\n",
       "10              WeekDay         653\n",
       "11          AgeCategory         122\n",
       "12  WaitingTimeCategory          43\n",
       "13      TotalConditions         339"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b1a73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "910f009e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>2546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeGapDays</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeekDay</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prevNoshow</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TotalConditions</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMSreceived</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GenderM</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scholarship</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alcoholism</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AgeCategory</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Handcap</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hipertension</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WaitingTimeCategory</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature Name  Importance\n",
       "1                   Age        2546\n",
       "8           TimeGapDays        1729\n",
       "10              WeekDay         653\n",
       "9            prevNoshow         404\n",
       "13      TotalConditions         339\n",
       "0           SMSreceived         308\n",
       "2               GenderM         253\n",
       "3           Scholarship         153\n",
       "6            Alcoholism         152\n",
       "11          AgeCategory         122\n",
       "7               Handcap         118\n",
       "4          Hipertension         111\n",
       "5              Diabetes          99\n",
       "12  WaitingTimeCategory          43"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3b576c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(feature_importance_df['Feature Name'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a22b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
